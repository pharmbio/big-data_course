{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a QSAR model using the Morgan fingerprint in rdkit and Random forest from Spark's Machine Learning\n",
    "\n",
    "## QSAR\n",
    "We know that the structure of a molecule detmerines the molecules properties but we are not capable of calculating molecular properties from molecular structures in general. One approach to doing this is used in the field of Quantitative Structure-Activity Relationships (QSAR) / Quantitative Structure-Property Relationship (QSPR) where a molecular structure is mathematically described and then machine learning is used to predict molecular activity or molecular properties. The names QSAR and QSPR are sometimes used a bit sloppy and mixed up, QSAR seems to be the most common term but QSPR is arguably a bit more general. So we need a strategy for describing the molecular properties, a machine larning algorithm and a lot of data that we can use to train our machine larning algorithm on.\n",
    "\n",
    "### Molecular descriptor\n",
    "A molecular descriptor is a mathematical representation of a molecule resulting from the transformation of the symbolic representation of a molecule into numbers. A simple approach might simply be to count the number of different atoms or fragments. There are many different approaches, some calculated from the matrix resulting from the pairwise distances between all atoms in the molecule, some being fragment based. The idea is to create a vector of numbers calcualted in such a way that similar compounds will have similar vectors. There are two different approaches worth mentioning. Either each posiition in the vector is predefined and map to one thing meaning that we know exactly what each position means, (_e.g._, if a position in the vector has the number 1 we know that the molecule contains exactly the substructure that corresponds to that position), or a _hashing_ algorithm is used to go from a descriptor to a position in the vector. The hashing algorithm is a one-way algorithm that turns, _e.g._, a string into a number (corresponding to the position in the vector). The hashing approach has the benefit that it does not require someone to predefine which structures should be used, anything found can be hashed and used in the vector but we can not easily know what each position means, and there is the risk for hash collisions (_i.e._, the hashing algorithm mapping many things into the same number making it impossible to say which one it originally was). In this lab we will use a circular fingerpint known as the Morgan fingerprint as implemented in the Python library RDKit and hash it down to a vector. A circular fingerprint uses each atom in a molecular and describe the atom neighbours out to a certain distance or \"radius\".\n",
    "\n",
    "### Machine learning algorithm\n",
    "We will use the Random Forest alogithm which is a good algorithm to start with. We will not go into detail on how the algorithm works in this lab but it constructs a multitude of decission trees and then weight them together.\n",
    "\n",
    "### Dataset\n",
    "The data we willl look at in this lab is distribution coefficient, log D, we will use a calculated value that we have extracted from a database where this number has been calculated for many substances. Since we want to work with big data we will use a calculated value. Of course the quality of the model depends heavily on the number of training examples and we will try with different sizes in this lab and see how the model improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5b80e2299a0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataStructs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump_svmlight_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "import numpy as np\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SimpleApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\",\"true\")\\\n",
    "               .option(\"delimiter\", '\\t').csv(\"acd_logd.smiles\")\\\n",
    "               .sample(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.select(\"canonical_smiles\", \"acd_logd\").rdd.map( lambda row: (row.canonical_smiles, float(row.acd_logd)) )\\\n",
    "         .map( lambda x: (Chem.MolFromSmiles(x[0]), x[1]) )\\\n",
    "         .map( lambda x: (AllChem.GetMorganFingerprintAsBitVect(x[0], 2, nBits=4096), x[1]) )\\\n",
    "         .map( lambda x: (np.array(x[0]),x[1]) )\\\n",
    "         .map( lambda x: (Vectors.dense(x[0].tolist()),x[1]) )\\\n",
    "         .map( lambda x: (x[0],x[1]))\\\n",
    "         .toDF([\"features\", \"label\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "rfModel = model.stages[1]\n",
    "print(rfModel)  # summary only\n",
    "\n",
    "spark.stop()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit",
   "language": "python",
   "name": "rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
